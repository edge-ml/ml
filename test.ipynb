{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "from db.binStore.binaryStore import BinaryStore\n",
    "from db.datasets import get_dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# Simulated Input\n",
    "datasetIds = [\"6412ce0cf822bfe2b57fea8f\", \"6412ce0cf822bfe2b57feaa8\", \"6412ce0cf822bfe2b57fead1\", \"6412ce0cf822bfe2b57feae3\"]\n",
    "project = \"640842f05e144be461cef648\"\n",
    "labeling_id = \"6412cb71f822bfe2b57fe96e\"\n",
    "ts = [\"6412ce0cf822bfe2b57fea90\", \"6412ce0cf822bfe2b57fea91\", \"6412ce0cf822bfe2b57fea92\"]\n",
    "\n",
    "labelings = {\"Square\": \"6412cb71f822bfe2b57fe96d\", \"W\": \"6412cb71f822bfe2b57fe973\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"datasets.json\", \"r\") as f:\n",
    "    all_datasets = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "# Get relevant datasets\n",
    "\n",
    "datasets = []\n",
    "for d in all_datasets:\n",
    "    if (str(d[\"_id\"][\"$oid\"]) in datasetIds):\n",
    "        datasets.append(d)\n",
    "print(len(datasets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build mal for labelings. Label => Number\n",
    "\n",
    "labelMap = {\"6412cb71f822bfe2b57fe96d\": 1, \"6412cb71f822bfe2b57fe973\": 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(135, 3, 8)\n",
      "(53, 3, 8)\n",
      "(133, 3, 8)\n",
      "(99, 3, 8)\n",
      "--------------------------------------------------\n",
      "(420, 3, 8)\n",
      "(420,)\n",
      "Acc:  1.0\n"
     ]
    }
   ],
   "source": [
    "# Process each dataset\n",
    "\n",
    "\n",
    "def processDataset(dataset):\n",
    "    \n",
    "    # Get labels in datasets\n",
    "    labels = [x for x in dataset[\"labelings\"] if x[\"labelingId\"][\"$oid\"] == labeling_id][0][\"labels\"]\n",
    "    # Get the time-series\n",
    "    dfs = []\n",
    "    \n",
    "    for ts in dataset[\"timeSeries\"]:\n",
    "        binStore = BinaryStore(ts[\"_id\"]['$oid'])\n",
    "        binStore.loadSeries()\n",
    "        ts_data = binStore.getFull()\n",
    "        data = ts_data[\"data\"]\n",
    "        time = ts_data[\"time\"]\n",
    "        df = pd.DataFrame({\"time\": time, ts[\"name\"]: data})\n",
    "        dfs.append(df)\n",
    "\n",
    "\n",
    "    # Merge the dataframes\n",
    "    df = dfs[0]\n",
    "    for d in dfs[1:]:\n",
    "        df = pd.merge(df, d, how='outer', on=\"time\")\n",
    "\n",
    "    df = df.interpolate(method='linear', limit_direction='both')\n",
    "    \n",
    "    dims = df.columns\n",
    "    arr = df.to_numpy()\n",
    "    label_arr = np.empty((arr.shape[0], 1))\n",
    "\n",
    "    arr = np.concatenate([arr, label_arr], axis=1)\n",
    "\n",
    "    for i, t in enumerate(arr):\n",
    "        for l in labels:\n",
    "            if t[0] >= int(l[\"start\"]) and t[0] <= int(l[\"end\"]):\n",
    "                arr[i][-1] = labelMap[l[\"type\"]['$oid']]\n",
    "                break\n",
    "            else:\n",
    "                arr[i][-1] = 0\n",
    "    \n",
    "    return arr\n",
    "\n",
    "def getDatasetWindows(dataset, window_size, stride):\n",
    "    window_size = 100\n",
    "    stride = 20\n",
    "\n",
    "    fused = []\n",
    "    idx = 0\n",
    "    while idx < dataset.shape[0]:\n",
    "        if idx+window_size > dataset.shape[0]:\n",
    "            break\n",
    "        fused.append(dataset[idx: idx+window_size])\n",
    "        idx += stride\n",
    "\n",
    "    labels = []\n",
    "    windows = []\n",
    "\n",
    "    for w in fused:\n",
    "        windows.append(w[:, :-1])\n",
    "        counts = np.bincount(w[:,-1].astype(int))\n",
    "        label = np.argmax(counts)\n",
    "        labels.append(label)\n",
    "\n",
    "    windows = np.array(windows)\n",
    "    labels = np.array(labels)\n",
    "    return windows, labels\n",
    "\n",
    "\n",
    "features = [np.sum, np.median, np.mean, np.std, np.var, np.max, lambda x : np.abs(np.max(x)), np.min]\n",
    "\n",
    "def extract_features(data):\n",
    "    return np.array([f(data) for f in features])\n",
    "\n",
    "\n",
    "def calculateFeatures(windows):\n",
    "    window_features = []\n",
    "    for w in windows:\n",
    "        stack = []\n",
    "        for i in range(1, windows.shape[-1]):\n",
    "            stack.append(extract_features(w[:, i]))\n",
    "        window_features.append(np.stack(stack))\n",
    "\n",
    "    return np.array(window_features)    \n",
    "\n",
    "\n",
    "def trainClassifier(windows, labels):\n",
    "    clf = DecisionTreeClassifier()\n",
    "\n",
    "    # Reshape the windows\n",
    "    windows = np.reshape(windows, (windows.shape[0], np.multiply(*windows.shape[1:])))\n",
    "    \n",
    "    clf.fit(windows, labels)\n",
    "    y_pred = clf.predict(windows)\n",
    "    acc = accuracy_score(labels, y_pred)\n",
    "    print(\"Acc: \", acc)\n",
    "\n",
    "    pass\n",
    "\n",
    "all_windows = []\n",
    "all_labels = []\n",
    "for dataset in datasets:\n",
    "    arr = processDataset(dataset)\n",
    "    windows, labels = getDatasetWindows(arr, window_size=50, stride=20)\n",
    "    windows = calculateFeatures(windows)\n",
    "    print(windows.shape)\n",
    "    all_windows.append(windows)\n",
    "    all_labels.extend(labels)\n",
    "\n",
    "all_windows = np.concatenate(all_windows, axis=0)\n",
    "all_labels = np.array(all_labels)\n",
    "print(\"-\"*50)\n",
    "print(all_windows.shape)\n",
    "print(all_labels.shape)\n",
    "filter = np.array([x > 0 for x in all_labels])\n",
    "\n",
    "all_windows = all_windows[filter]\n",
    "all_labels = all_labels[filter]\n",
    "\n",
    "\n",
    "trainClassifier(all_windows, all_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'start': 263288, 'end': 266220, 'type': {'$oid': '6412cb71f822bfe2b57fe96d'}, '_id': {'$oid': '6412ce0cf822bfe2b57fea93'}, 'metaData': {}}, {'start': 267290, 'end': 269944, 'type': {'$oid': '6412cb71f822bfe2b57fe96d'}, '_id': {'$oid': '6412ce0cf822bfe2b57fea94'}, 'metaData': {}}, {'start': 271173, 'end': 274303, 'type': {'$oid': '6412cb71f822bfe2b57fe96d'}, '_id': {'$oid': '6412ce0cf822bfe2b57fea95'}, 'metaData': {}}, {'start': 275848, 'end': 277949, 'type': {'$oid': '6412cb71f822bfe2b57fe96d'}, '_id': {'$oid': '6412ce0cf822bfe2b57fea96'}, 'metaData': {}}, {'start': 278979, 'end': 281277, 'type': {'$oid': '6412cb71f822bfe2b57fe96d'}, '_id': {'$oid': '6412ce0cf822bfe2b57fea97'}, 'metaData': {}}, {'start': 283099, 'end': 286031, 'type': {'$oid': '6412cb71f822bfe2b57fe96d'}, '_id': {'$oid': '6412ce0cf822bfe2b57fea98'}, 'metaData': {}}, {'start': 288171, 'end': 290825, 'type': {'$oid': '6412cb71f822bfe2b57fe96d'}, '_id': {'$oid': '6412ce0cf822bfe2b57fea99'}, 'metaData': {}}, {'start': 292450, 'end': 295540, 'type': {'$oid': '6412cb71f822bfe2b57fe96d'}, '_id': {'$oid': '6412ce0cf822bfe2b57fea9a'}, 'metaData': {}}, {'start': 297442, 'end': 299898, 'type': {'$oid': '6412cb71f822bfe2b57fe96d'}, '_id': {'$oid': '6412ce0cf822bfe2b57fea9b'}, 'metaData': {}}, {'start': 302711, 'end': 306079, 'type': {'$oid': '6412cb71f822bfe2b57fe96d'}, '_id': {'$oid': '6412ce0cf822bfe2b57fea9c'}, 'metaData': {}}, {'start': 308615, 'end': 311746, 'type': {'$oid': '6412cb71f822bfe2b57fe96d'}, '_id': {'$oid': '6412ce0cf822bfe2b57fea9d'}, 'metaData': {}}, {'start': 314361, 'end': 317412, 'type': {'$oid': '6412cb71f822bfe2b57fe96d'}, '_id': {'$oid': '6412ce0cf822bfe2b57fea9e'}, 'metaData': {}}, {'start': 320383, 'end': 323157, 'type': {'$oid': '6412cb71f822bfe2b57fe96d'}, '_id': {'$oid': '6412ce0cf822bfe2b57fea9f'}, 'metaData': {}}, {'start': 327040, 'end': 330447, 'type': {'$oid': '6412cb71f822bfe2b57fe96d'}, '_id': {'$oid': '6412ce0cf822bfe2b57feaa0'}, 'metaData': {}}, {'start': 331874, 'end': 334766, 'type': {'$oid': '6412cb71f822bfe2b57fe96d'}, '_id': {'$oid': '6412ce0cf822bfe2b57feaa1'}, 'metaData': {}}, {'start': 337302, 'end': 340630, 'type': {'$oid': '6412cb71f822bfe2b57fe96d'}, '_id': {'$oid': '6412ce0cf822bfe2b57feaa2'}, 'metaData': {}}, {'start': 343166, 'end': 345939, 'type': {'$oid': '6412cb71f822bfe2b57fe96d'}, '_id': {'$oid': '6412ce0cf822bfe2b57feaa3'}, 'metaData': {}}, {'start': 348555, 'end': 351962, 'type': {'$oid': '6412cb71f822bfe2b57fe96d'}, '_id': {'$oid': '6412ce0cf822bfe2b57feaa4'}, 'metaData': {}}, {'start': 353705, 'end': 356717, 'type': {'$oid': '6412cb71f822bfe2b57fe96d'}, '_id': {'$oid': '6412ce0cf822bfe2b57feaa5'}, 'metaData': {}}, {'start': 358737, 'end': 362065, 'type': {'$oid': '6412cb71f822bfe2b57fe96d'}, '_id': {'$oid': '6412ce0cf822bfe2b57feaa6'}, 'metaData': {}}, {'start': 363650, 'end': 366820, 'type': {'$oid': '6412cb71f822bfe2b57fe96d'}, '_id': {'$oid': '6412ce0cf822bfe2b57feaa7'}, 'metaData': {}}]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(\"datasets.json\", \"r\") as f:\n",
    "    datasets = json.load(f)\n",
    "\n",
    "dataset = None\n",
    "for d in datasets:\n",
    "    if (d[\"_id\"][\"$oid\"] == datasetId):\n",
    "        dataset = d\n",
    "\n",
    "labels = [x for x in dataset[\"labelings\"] if x[\"labelingId\"][\"$oid\"]][0][\"labels\"]\n",
    "print(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "binStore = BinaryStore(ts[0])\n",
    "binStore.loadSeries()\n",
    "data = binStore.getFull()\n",
    "time = data[\"time\"]\n",
    "data = data[\"data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "d = np.array([time, data])\n",
    "n = np.empty((1, len(time)))\n",
    "\n",
    "d = np.concatenate([d, n]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2780, 3)\n"
     ]
    }
   ],
   "source": [
    "print(d.shape)\n",
    "\n",
    "for i, t in enumerate(d):\n",
    "    for l in labels:\n",
    "        if t[0] >= int(l[\"start\"]) and t[0] <= int(l[\"end\"]):\n",
    "            d[i][2] = 1\n",
    "            break\n",
    "        else:\n",
    "            d[i][2] = 0\n",
    "\n",
    "np.savetxt(\"test.csv\", d, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "\n",
    "window_size = 100\n",
    "stride = 20\n",
    "\n",
    "fused = []\n",
    "\n",
    "while idx < d.shape[0]:\n",
    "    if idx+window_size > d.shape[0]:\n",
    "        break\n",
    "    fused.append(d[idx: idx+window_size])\n",
    "    idx += stride\n",
    "\n",
    "labels = []\n",
    "windows = []\n",
    "\n",
    "for w in fused:\n",
    "    windows.append(w[:, :-1])\n",
    "    counts = np.bincount(w[:,2].astype(int))\n",
    "    label = np.argmax(counts)\n",
    "    labels.append(label)\n",
    "\n",
    "windows = np.array(windows)\n",
    "labels = np.array(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(135, 1, 8)\n",
      "135\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "features = [np.sum, np.median, np.mean, np.std, np.var, np.max, lambda x : np.abs(np.max(x)), np.min]\n",
    "\n",
    "def extract_features(data):\n",
    "    return np.array([f(data) for f in features])\n",
    "\n",
    "\n",
    "\n",
    "window_features = []\n",
    "for w in windows:\n",
    "    stack = []\n",
    "    for i in range(1, windows.shape[-1]):\n",
    "        stack.append(extract_features(w[:, i]))\n",
    "    window_features.append(np.stack(stack))\n",
    "\n",
    "window_features = np.array(window_features)\n",
    "\n",
    "print(window_features.shape)\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(135, 8)\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "windows_train = np.reshape(window_features, (len(window_features), np.multiply(*window_features.shape[1:])))\n",
    "\n",
    "print(windows_train.shape)\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "clf.fit(windows_train, labels)\n",
    "y_pred = clf.predict(windows_train)\n",
    "acc = accuracy_score(labels, y_pred)\n",
    "print(acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('edgeml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7cdee8c70ec73ad090e1f28a368e8b32f100bb8dbe7a0bb888718bd320f086b2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
